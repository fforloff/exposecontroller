package main

import (
	"encoding/json"
	"flag"
	"fmt"
	"net/http"
	"net/http/pprof"
	"os"
	"strings"
	"time"

	"github.com/golang/glog"
	"github.com/olli-ai/exposecontroller/controller"
	"github.com/olli-ai/exposecontroller/exposestrategy"

	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
	"k8s.io/apimachinery/pkg/util/wait"
	"k8s.io/client-go/kubernetes"
	"k8s.io/client-go/rest"
	"k8s.io/client-go/tools/cache"
	"k8s.io/client-go/tools/clientcmd"
)

const (
	healthPort = 10254
)

var (
	configFile = flag.String("config", "/etc/exposecontroller/config.yml",
		`Path to the file that contains the exposecontroller configuration to use`)

	resyncPeriod = flag.Duration("sync-period", 30*time.Second,
		`Relist and confirm services this often.`)

	healthzPort = flag.Int("healthz-port", healthPort, "port for healthz endpoint.")

	profiling = flag.Bool("profiling", true, `Enable profiling via web interface host:port/debug/pprof/`)

	daemon  = flag.Bool("daemon", false, `Run as daemon mode watching changes as it happens.`)
	cleanup = flag.Bool("cleanup", false, `Removes Ingress rules that were generated by exposecontroller`)

	domain                = flag.String("domain", "", "Domain to use with your DNS provider (default: .nip.io).")
	filter                = flag.String("filter", "", "The filter of service names to look for when cleaning up")
	exposer               = flag.String("exposer", "", "Which strategy exposecontroller should use to access applications")
	apiserver             = flag.String("api-server", "", "API server URL")
	consoleurl            = flag.String("console-server", "", "Console URL")
	httpb                 = flag.Bool("http", false, `Use HTTP`)
	watchNamespaces       = flag.String("watch-namespace", "", "Exposecontroller will only look at the provided namespace")
	watchCurrentNamespace = flag.Bool("watch-current-namespace", true, `Exposecontroller will look at the current namespace only - (default: 'true' unless --watch-namespace specified)`)
	services              = flag.String("services", "", "List of comma separated service names which will be exposed, if empty all services from namespace will be considered")
)

func main() {
	flag.Parse()

	var restClientConfig *rest.Config
	var err error
	if *configFile == "" {
		glog.Infof("using in-cluster configuration")
		restClientConfig, err = rest.InClusterConfig()
	} else {
		glog.Infof("using configuration from '%s'", *configFile)
		restClientConfig, err = clientcmd.BuildConfigFromFlags("", *configFile)
	}
	if err != nil {
		glog.Fatalf("failed to create REST client config: %s", err)
	}

	kubeClient, err := kubernetes.NewForConfig(restClientConfig)
	for i := 0; i < 30; i++ {
		if err != nil {
			glog.Warningf("failed to create client, retrying: %s", err)
			time.Sleep(1 * time.Second)
			kubeClient, err = kubernetes.NewForConfig(restClientConfig)
		} else {
			break
		}
	}
	if err != nil {
		glog.Fatalf("failed to create client: %s", err)
	}
	currentNamespace := os.Getenv("KUBERNETES_NAMESPACE")
	if len(currentNamespace) == 0 {
		currentNamespace = metav1.NamespaceDefault
	}

	controllerConfig, exists, err := controller.LoadFile(*configFile)
	if !exists || err != nil {
		if err != nil {
			glog.Warningf("failed to load config file: %s", err)
		}

		cc2 := tryFindConfig(kubeClient, currentNamespace)
		if cc2 == nil {
			// lets try find the ConfigMap in the dev namespace
			resource, err := kubeClient.CoreV1().Namespaces().Get(currentNamespace, metav1.GetOptions{})
			if err == nil && resource != nil {
				labels := resource.Labels
				if labels != nil {
					ns := labels["team"]
					if ns == "" {
						glog.Warningf("No 'team' label on Namespace %s", currentNamespace)
					} else {
						glog.Infof("trying to find the ConfigMap in the Dev Namespace %s", ns)

						cc2 = tryFindConfig(kubeClient, ns)
					}
				} else {
					glog.Warningf("No labels on Namespace %s", currentNamespace)
				}
			} else {
				glog.Warningf("Failed to load Namespace %s: %s", currentNamespace, err)

				// lets try default to trimming the lasts path from the current namespace
				idx := strings.LastIndex(currentNamespace, "-")
				if idx > 1 {
					ns := currentNamespace[0:idx]
					cc2 = tryFindConfig(kubeClient, ns)
				}
			}
		}
		if cc2 != nil {
			controllerConfig = cc2
		}
	} else {
		glog.Infof("Loaded config file %s", *configFile)
	}
	glog.Infof("Config file before overrides %s", controllerConfig.String())

	if *domain != "" {
		controllerConfig.Domain = *domain
	}
	if *exposer != "" {
		controllerConfig.Exposer = *exposer
	}
	if *apiserver != "" {
		controllerConfig.ApiServer = *apiserver
	}
	if *consoleurl != "" {
		controllerConfig.ConsoleURL = *consoleurl
	}
	if *httpb {
		controllerConfig.HTTP = *httpb
	}

	if *watchCurrentNamespace {
		controllerConfig.WatchCurrentNamespace = *watchCurrentNamespace
	}
	if *watchNamespaces != "" {
		controllerConfig.WatchNamespaces = *watchNamespaces
		controllerConfig.WatchCurrentNamespace = false
	}

	if *services != "" {
		controllerConfig.Services = strings.Split(*services, ",")
	}

	glog.Infof("Config file after overrides %s", controllerConfig.String())

	//watchNamespaces := metav1.NamespaceAll
	watchNamespaces := controllerConfig.WatchNamespaces
	if controllerConfig.WatchCurrentNamespace {
		if len(currentNamespace) == 0 {
			glog.Fatalf("No current namespace found!")
		}
		watchNamespaces = currentNamespace
	}

	if *cleanup {
		err = exposestrategy.CleanIngressStrategy(kubeClient, watchNamespaces)
		if err != nil {
			glog.Fatalf("Could not clean: %v", err)
		}
		return
	}

	if *daemon {
		glog.Infof("Watching services in namespaces: `%s`", watchNamespaces)
		contr, err := controller.ControllerDaemon(kubeClient, *resyncPeriod, watchNamespaces, controllerConfig)
		if err == nil {
			go registerHandlers(contr)
			contr.Run(wait.NeverStop)
		}
	} else {
		glog.Infof("Running in : `%s`", watchNamespaces)
		err = controller.RunController(kubeClient, watchNamespaces, controllerConfig)
	}

	if err != nil {
		glog.Fatalf("%s", err)
	}
}

func tryFindConfig(kubeClient kubernetes.Interface, ns string) *controller.Config {
	var controllerConfig *controller.Config
	cm, err := kubeClient.CoreV1().ConfigMaps(ns).Get("exposecontroller", metav1.GetOptions{})
	if err == nil {
		glog.Infof("Using ConfigMap exposecontroller to load configuration...")
		// TODO we could allow the config to be passed in via key/value pairs?
		text := cm.Data["config.yml"]
		if text != "" {
			controllerConfig, err = controller.Load(text)
			if err != nil {
				glog.Warningf("Could not parse the config text from exposecontroller ConfigMap  %v", err)
			}
			glog.Infof("Loaded ConfigMap exposecontroller to load configuration!")
		}
	} else {
		glog.Warningf("Could not find ConfigMap exposecontroller ConfigMap in namespace %s", ns)

		cm, err = kubeClient.CoreV1().ConfigMaps(ns).Get("ingress-config", metav1.GetOptions{})
		if err != nil {
			glog.Warningf("Could not find ConfigMap ingress-config ConfigMap in namespace %s", ns)
		} else {
			glog.Infof("Loaded ConfigMap ingress-config to load configuration!")
			data := cm.Data
			if data != nil {
				controllerConfig, err = controller.MapToConfig(data)
				if err != nil {
					glog.Warningf("Failed to convert Map data %#v from configMap ingress-config in namespace %s due to: %s\n", controllerConfig, ns, err)
				}
			}
		}
	}
	return controllerConfig
}

func registerHandlers(controller cache.Controller) {
	mux := http.NewServeMux()
	mux.HandleFunc("/healthz", func(res http.ResponseWriter, req *http.Request) {
		ready := controller.HasSynced()

		if ready {
			res.WriteHeader(http.StatusServiceUnavailable)
		} else {
			res.WriteHeader(http.StatusOK)
		}

		enc := json.NewEncoder(res)
		_ = enc.Encode(map[string]interface{}{
			"ready": ready,
		})
	})

	if *profiling {
		mux.HandleFunc("/debug/pprof/", pprof.Index)
		mux.HandleFunc("/debug/pprof/profile", pprof.Profile)
		mux.HandleFunc("/debug/pprof/symbol", pprof.Symbol)
	}

	server := &http.Server{
		Addr:    fmt.Sprintf(":%v", *healthzPort),
		Handler: mux,
	}
	glog.Fatal(server.ListenAndServe())
}
